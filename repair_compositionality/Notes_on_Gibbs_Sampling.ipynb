{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Gibbs sampling and the Chinese restaurant process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis algorithm, Metropolis-Hastings, and Gibbs sampling:\n",
    "\n",
    "### Differences between Gibbs sampling and Metropolis algorithm:\n",
    "\n",
    "- Gibbs sampling is more efficient at exploring the parameter space, because unlike in the random walk Metropolis algorithm, it accepts _all_ proposals\n",
    "- However, the conditions for being able to use Gibbs sampling are more stringent, because we need to _know_ the conditional probability distribution for each $\\theta$ (i.e. each hypothesis in our case), given specific values of each other $\\theta$ (i.e. each other hypothesis in our case), _and_ we need to be able to independently sample from them.\n",
    "- If there is a high degree of correlation between parameters, Gibbs sampling can be very slow. --> if this is a problem, it might make sense to sample in _blocks_ of parameters; e.g. $\\theta_{1}, \\theta_{2} \\sim P(\\theta_{1}, \\theta_{2} \\mid \\theta_{3})$ (although often it's even harder to derive such a multivariate conditional probability distribution than it is to derive a univariate distribution like $\\theta_{1} \\sim P(\\theta_{1} \\mid \\theta_{2}, \\theta_{3})$).\n",
    "\n",
    "### Differences between Metropolis and Metropolis-Hastings:\n",
    "\n",
    "In the Metropolis algorithm, proposals need to be drawn from a _symmetric_ distribution centered around the current position (i.e. the current $\\theta$). This means that the probability of jumping from $\\theta_{a}$ to $\\theta_{b}$ should be the same as the probability of jumping from $\\theta_{b}$ to $\\theta_{a}$ (i.e. $P(\\theta_{b}$, $\\theta_{a}) = P(\\theta_{a}$, $\\theta_{b})$. This condition is for instance met by the normal distribution centered around the current $\\theta$, that is why the normal distribution is often used as the proposal distribution (also known as 'jumping distribution'). (Or, to use the example of King Markov, ruler of the Monte Carlo archipelago, from Richard McElreath's book: In order to propose which island to go to next, King Markov flips a fair coin, where heads means to go to the island on the right, and tails means to go to the island on the left.)\n",
    "\n",
    "\n",
    "In the Metropolis-Hastings algorithm, proposal distributions do _not_ need to be symmetrical. This is useful because it allows you to make more intelligent proposals, which allows the algorithm to do more efficient tours and therefore converge faster. Metropolis-Hastings can also be thought of as a more general version of the Metropolis algorithm\n",
    "\n",
    "\n",
    "### Differences between Metropolis-Hastings and Gibbs sampling:\n",
    "\n",
    "Gibbs sampling in turn is an efficient version of the Metropolis-Hastings algorithm; it uses a very clever proposal distribution. It uses adaptive proposals, where \"the distribution of proposed parameter values adjusts itself intelligently, depending upon the parameter values at the moment\" (McElreath, Statistical Rethinking, new draft, p. 269).\n",
    "\n",
    "### What they all have in common:\n",
    "\n",
    "The Metropolis algorithm, Metropolis-Hastings algorithm, and Gibbs sampling all have in common that they use \"guess and check\" strategies. They guess a new proposal position (i.e. parameter setting), check the posterior probability at that new position against the posterior probability at the current position, and decide what to do next based on that.\n",
    "\n",
    "---> This \"guess and check\" strategy has as a consequence that the **quality of the proposals** is the most important thing. Because if you make dumb proposals, you'll reject them all, and the algorithm will take ages to converge. The **goal is to accept every proposal** (and this is in fact what Gibbs sampling does), because if you'd constantly be moving, you'd tour the space as fast as possible.\n",
    "\n",
    "### How Gibbs sampling is implemented in Bayesian inference:\n",
    "\n",
    "> \"How Gibbs sampling computes these adaptive proposals depends upon particular combinations of prior distributions and likelihoods known as _conjugate pairs_. Conjugate pairs have analytical solutions for the posterior distribution of an individual parameter. And these solutions are what allow Gibbs sampling to make smart jumps around the joint posterior distribution of all parameters.\" (McElreath, Statistical Rethinking, new draft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
